## 神经网络文本分类

### TextCNN

#### 网络结构

#### 实验结果

实验在下面几方面做了变化：

基于字/基于词：

+ 基于字的模型，

学习率更新：

+ 尝试了基于字的模型，基于 jieba 切分词（去除停用词）的模型。
+ 学习率更新，尝试了不用 scheduler、cosine scheduler。

下图为验证集精确度曲线，蓝色为词，橙色为字，基于词的收敛较快，基于字的 20 epoches 后精确度稍高。

基于字，默认参数训练得到的结果如下。

| class | precision | recall | F1 score |
| ----- | --------- | ------ | -------- |
| 奥运  | 0.9656    | 0.8682 | 0.9143   |
| 房产  | 0.8955    | 0.9142 | 0.9047   |
| 商业  | 0.8446    | 0.9058 | 0.8741   |
| 娱乐  | 0.9454    | 0.9445 | 0.9450   |

可以看到，商业的 precision 是最差的，它涵盖的文本内容与其他交叉最多，容易将其他的也分成商业。奥运的 recall 最差。

基于词，默认参数训练得到的结果如下。

| class | precision | recall | F1 score |
| ----- | --------- | ------ | -------- |
| 奥运  | 0.9037    | 0.9127 | 0.9082   |
| 房产  | 0.9037    | 0.8683 | 0.8857   |
| 商业  | 0.8591    | 0.8942 | 0.8763   |
| 娱乐  | 0.9292    | 0.9182 | 0.9236   |
从字改成词，最显著的影响是奥运的 recall 上升，因为“奥运”一词在确定这一分类时权重极大。


### BiLSTM



### BiLSTM + CNN

              precision    recall  f1-score   support
    
       aoyun     0.9236    0.9236    0.9236      1100
    fangchan     0.9201    0.8925    0.9061      1200
     shangye     0.8622    0.9075    0.8843      1200
        yule     0.9497    0.9264    0.9379      1100
    
    accuracy                         0.9120      4600

### BiLSTM + Attention